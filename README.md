# ðŸ“¡ Satellite Signal Strength Prediction  
### A Supervised Regression Pipeline for Estimating Signal Quality from Weather Conditions

---

## Overview

This project builds regression models to predict **satellite signal strength (in dBm)** using weather and atmospheric data. It follows a structured, reproducible workflow:

- **Simple Linear Regression** â€“ using rain rate as a predictor  
- **Multiple Regression** â€“ incorporating temperature, humidity, pressure, etc.  
- **Non-linear Models** â€“ Random Forest, XGBoost  
- **Advanced Optimization** â€“ feature engineering, hyperparameter tuning, SHAP analysis

---

## Business Relevance

Accurate signal prediction helps satellite internet providers:

- Maintain service quality during adverse weather  
- Proactively notify customers of potential disruptions  
- Optimize transmission power and resource allocation  
- Reduce downtime and improve customer satisfaction

---

## Technical Goals

- Collect real-time and historical weather data from public APIs  
- Simulate signal degradation using physics-inspired models  
- Build and evaluate regression algorithms with interpretable outputs  
- Identify key weather factors affecting signal strength  
- Create a reproducible, testable, and maintainable pipeline

---

## Tech Stack

- **Languages & Libraries**: `Python`, `pandas`, `numpy`, `scikit-learn`, `matplotlib`, `seaborn`, `xgboost`, `shap`, `requests`  
- **APIs**: `OpenWeatherMap` (free tier)  
- **Tools**: `Jupyter Notebook`, `PyCharm`, `Git`, `pytest`, `dotenv`, `yaml`  

---

## Location Coverage

Weather data is collected from diverse global locations to ensure model generalization:

- Seattle ðŸ‡ºðŸ‡¸  
- Chicago ðŸ‡ºðŸ‡¸  
- Phoenix ðŸ‡ºðŸ‡¸  
- Miami ðŸ‡ºðŸ‡¸  
- Denver ðŸ‡ºðŸ‡¸  
- San Francisco ðŸ‡ºðŸ‡¸  
- New York ðŸ‡ºðŸ‡¸  
- London ðŸ‡¬ðŸ‡§  
- Tokyo ðŸ‡¯ðŸ‡µ  
- Sydney ðŸ‡¦ðŸ‡º  

---

## Project Structure
```
Satellite-Signal-Prediction/
â”‚  â”œâ”€â”€ data/ 
â”‚  â”œâ”€â”€ raw/ # Unprocessed weather data from API 
â”‚  â”œâ”€â”€ processed/ # Cleaned and feature-engineered datasets 
â”‚  â””â”€â”€ simulated/ # Datasets with simulated signal strength  
â”‚
â”œâ”€â”€ notebooks/ 
â”‚  â”œâ”€â”€ 01_exploration.ipynb #Initial data exploration 
â”‚  â”œâ”€â”€ 02_modeling_baseline.ipynb # Linear regression 
â”‚  â””â”€â”€ 03_modeling_advanced.ipynb # Non-linear models and tuning 
â”‚ 
â”œâ”€â”€ results/
â”‚  â”œâ”€â”€ figures/ # Plots and visualizations 
â”‚  â”œâ”€â”€ models/ # Saved model files
â”‚  â””â”€â”€ reports/ # Summary reports and metrics 
â”‚
â”œâ”€â”€ src/ 
â”‚   â”œâ”€â”€ data_collection.py # Weather API scripts 
â”‚   â”œâ”€â”€ data_validation.py # Schema and quality checks 
â”‚   â”œâ”€â”€ signal_simulation.py # Signal strength simulation logic
â”‚   â”œâ”€â”€ preprocessing.py # Data cleaning and feature engineering
â”‚   â”œâ”€â”€ modeling.py # Model training and evaluation
â”‚   â”œâ”€â”€ open_meteo_historical.py # Gather Historical data
â”‚   â”œâ”€â”€ validate_weather_data.py # Historical data validation 
â”‚   â””â”€â”€ utils/ 
â”‚       â”œâ”€â”€ logger.py 
â”‚       â”œâ”€â”€ config_loader.py
â”‚       â”œâ”€â”€ constants.py
â”‚       â””â”€â”€ helpers.py
â”‚ 
â”œâ”€â”€ tests/
â”‚  â”œâ”€â”€ test_data_collection.py # Unit tests for data collection
â”‚  â””â”€â”€ test_data_validation.py # Unit tests for validation logic
â”‚  
â”œâ”€â”€ .env # Environment variables (e.g. API keys)
â”œâ”€â”€ config.yaml # Optional config file for project root
â”œâ”€â”€ .gitignore # Git exclusions
â”œâ”€â”€ LICENSE # Project license
â”œâ”€â”€ main.py # Entry point (optional)
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ project.llm
â””â”€â”€ requirements.txt # Python dependencies
```

---

## Testing Setup

To run tests locally or in CI:

### Option 1: Use Environment Variable

```
export PROJECT_ROOT=/Users/admin/Desktop/projects/signal_strength
```
### Option 2: Use `config.yaml`:
```
paths:
  project_root: /Users/admin/Desktop/projects/signal_strength
```
The test fixture processed_df will automatically load the latest processed weather data from data/processed/, or fall back to dummy data if none is found.

## Modeling Philosophy
This project avoids opaque automation and AI shortcuts. Every step is:

- Transparent and interpretable

- Executed manually or with traceable logic

- Designed for reproducibility and auditability

- Focused on real-world business relevance

## Author
Alireza Barzin Zanganeh 
Machine Learning Engineer | Backend & QA Automation
Committed to structure, transparency, and continuous improvement.

## License
MIT License. See LICENSE for details.